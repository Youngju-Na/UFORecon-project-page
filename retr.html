<!DOCTYPE html>
<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Rethinking Rendering in Generalizable Neural Surface Reconstruction: A Learning-based Solution</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://dorverbin.github.io/refnerf/img/refneus_titlecard.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://YixunLiang.github.io/">
    <meta property="og:title" content="ReTR: Modeling Rendering via Transformer for Generalizable Neural Surface Reconstruction">
    <meta property="og:description" content="Generalizable neural surface reconstruction techniques have attracted great attention in recent years. However, they encounter limitations of low confidence depth distribution and inaccurate surface reasoning due to the oversimplified volume rendering process employed. In this paper, we present Reconstruction TRansformer (ReTR), a novel framework that leverages the transformer architecture to redesign the rendering process, enabling complex photon-particle interaction modeling. It introduces a learnable meta-ray token and utilizes the cross-attention mechanism to simulate the interaction of photons with sampled points and render the observed color. Meanwhile, by operating within a high-dimensional feature space rather than the color space, ReTR mitigates sensitivity to projected colors in source views. Such improvements result in accurate surface assessment with high confidence. We demonstrate the effectiveness of our approach on various datasets, showcasing how our method outperforms the current state-of-the-art approaches in terms of reconstruction quality and generalization ability.">

    <!-- mirror: F0%9F%AA%9E&lt -->
    <link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text y=%22.9em%22 font-size=%2290%22&gt;%E2%9C%A8&lt;/text&gt;&lt;/svg&gt;">
    <link rel="stylesheet" href="static/css/bootstrap.min.css">
    <link rel="stylesheet" href="static/css/font-awesome.min.css">
    <link rel="stylesheet" href="static/css/codemirror.min.css">
    <link rel="stylesheet" href="static/css/app.css">

    <script src="static/js/jquery.min.js"></script>
    <script src="static/js/bootstrap.min.js"></script>
    <script src="static/js/codemirror.min.js"></script>
    <script src="static/js/clipboard.min.js"></script>
    <script src="static/js/video_comparison.js"></script>
    <script src="static/js/app.js"></script>
</head>

<body>
    <!-- <div class="container" id="header" style="text-align: center; margin: auto;">
        <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
            <h2 class="is-size-5 publication-authors" id="title">
                Rethinking Rendering in Generalizable Neural Surface Reconstruction:<br> A Learning-based Solution<br>
            </h2>
            <small>
                arXiv 2023
            </small>
        </div> -->
        <div class="container" id="main">
            <div class="row">
                <h2 class="col-md-12 text-center">
                    <b>ReTR</b>: Modeling Rendering via Transformer for <br>Generalizable Neural Surface Reconstruction<br>
                    <small>
                    NeurIPS 2023
                    </small>
                </h2>
            </div>
            <div class="row">
                <div class="col-md-12 text-center">
                    <ul class="list-inline">
                        <li>
                            <a href="https://yixunliang.github.io/">
                                Yixun Liang
                            </a><sup>1,2 *</sup>
                        </li>
                        <li>
                            <a href="">
                                Hao He
                            </a><sup>1,2 *</sup>
                        </li>
                        <li>
                            <a href="https://www.yingcong.me/">
                                Ying-Cong Chen
                            </a><sup>1,2</sup>
                        </li>
                        </br>                    
                        <div class="col-md-12 text-center" style="display: table; margin:0 auto">
                            <table class="author-table" id="author-table">
                                <tr>
                                    <td>
                                        <small>
                                        * Equal Contribution
                                        </small>
                                    </td>                    
                                <tr>
                            </table>
                        </div>
                        <span class="author-block"><sup>1</sup>HKUST(GZ)</span>&nbsp;&nbsp;
                        <span class="author-block"><sup>2</sup>HKUST</span>&nbsp;&nbsp;
                    </ul>
                </div>

        <!-- <div class="row" id="author-row" style="margin:0 auto;">
            <div class="col-md-12 text-center" style="display: table; margin:0 auto">
                <table class="author-table" id="author-table">
                    <tr>
                        <td>
                            <a style="text-decoration:none">
                            <a href="https://YixunLiang.github.io/">Yixun Liang</a><sup>1,2 *</sup>,
                        </td>
                        <td>
                            <a href="">Hao He</a><sup>1,2 *</sup>,</span>
                        </td>
                        <td>
                            <a href="https://www.yingcong.me/">Ying-Cong Chen</a><sup>1,2</sup>
                        </td>        
                    <tr>
                </table>
            </div>
            <div class="col-md-12 text-center" style="display: table; margin:0 auto">
                <table class="author-table" id="author-table">
                    <tr>
                        <td>
                        * Equal Contribution
                        </td>                    
                    <tr>
                    <span class="author-block"><sup>1</sup>HKUST(GZ)</span>&nbsp;&nbsp;
                    <span class="author-block"><sup>2</sup>HKUST</span>&nbsp;&nbsp;
                </table>
            </div>
        </div>
    </div> -->
    <script>
        document.getElementById('author-row').style.maxWidth = document.getElementById("title-row").clientWidth + 'px';
    </script>
    <div class="container" id="main">
        <div class="row">
                <div class="col-sm-6 col-sm-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/pdf/2305.18832.pdf">
                            <img src="./img/paper_img.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li> 
                        <li>
                            <a href="https://github.com/YixunLiang/ReTR" target="_blank">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b><p><font color="red">Note:</font></p></b>
                </h3>
                <p class="text-justify">
                <p><font color="red">we change our titile following the suggestions from reviewers/ACs, the camera-ready version paper and code will comming soon. <br>original name:<b>Rethinking Rendering in Generalizable Neural
Surface Reconstruction: A Learning-based Solution</b></font></p>
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Generalizable neural surface reconstruction techniques have attracted great attention in recent years. However, they encounter limitations of low confidence depth distribution and inaccurate surface reasoning due to the oversimplified volume rendering process employed. In this paper, we present Reconstruction TRansformer (ReTR), a novel framework that leverages the transformer architecture to redesign the rendering process, enabling complex photon-particle interaction modeling. It introduces a learnable meta-ray token and utilizes the cross-attention mechanism to simulate the interaction of photons with sampled points and render the observed color. Meanwhile, by operating within a high-dimensional feature space rather than the color space, ReTR mitigates sensitivity to projected colors in source views. Such improvements result in accurate surface assessment with high confidence. We demonstrate the effectiveness of our approach on various datasets, showcasing how our method outperforms the current state-of-the-art approaches in terms of reconstruction quality and generalization ability.
                </p>
            </div>
        </div>

        <image src="img/pipeline.png" class="img-responsive" alt="overview" width="60%" style="max-height: 450px;margin:auto;">

        <!-- Paper video. -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Proposed Method
                </h3>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="video/pipline_overview.mp4" type="video/mp4" />
                </video>
						</div>
        </div>
        <!--/ Paper video. -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Reconstruction Results
                </h3>

                <table width="110%">
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <div class="video-compare-container" display:block>
                                <video class="video" id="toaster_mesh" loop playsinline autoPlay muted src="static/videos/scan24_uforecon_best_unfavorable.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas height=0 class="videoMerge" id="toaster_meshMerge"></canvas>
                            </div>
                        </td>
                        <td align="left" valign="top" width="50%">
                            <div class="video-compare-container" display:block>
                                <video class="video" id="toaster_normals" loop playsinline autoPlay muted src="static/videos/scan24_uforecon_best_unfavorable.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas height=0 class="videoMerge" id="toaster_normalsMerge"></canvas>
                            </div>
                        </td>
                    </tr>
                </table>

                <table width="110%">
                    <tr>
                        <td align="left" valign="top" width="50%">
                            <div class="video-compare-container" display:block>
                                <video class="video" id="helmet_mesh" loop playsinline autoPlay muted src="static/videos/scan24_uforecon_best_unfavorable.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas height=0 class="videoMerge" id="helmet_meshMerge"></canvas>
                            </div>
                        </td>
                        <td align="left" valign="top" width="50%" display:block>
                            <div class="video-compare-container">
                                <video class="video" id="helmet_normals" loop playsinline autoPlay muted src="static/videos/scan24_uforecon_best_unfavorable.mp4" onplay="resizeAndPlay(this)"></video>
                                <canvas height=0 class="videoMerge" id="helmet_normalsMerge"></canvas>
                            </div>
                        </td>
                    </tr>
                </table>

			</div>
        </div>
            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{liang2023retr,
    author    = {Yixun Liang, Hao He, Ying-Cong Chen},
    title     = {Rethinking Rendering in Generalizable Neural Surface Reconstruction:
    A Learning-based Solution},
    journal   = {arXiv},
    year      = {2023},
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    <br>
                The website template was borrowed from <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
            </div>
        </div>
    </div>


</body></html>
